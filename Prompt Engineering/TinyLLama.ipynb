{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "Al8MMfi7c52a",
        "outputId": "a239925d-fd93-4080-a8da-c0827fc9effc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers==4.36.2 accelerate torch"
      ],
      "metadata": {
        "id": "Kn7BPtHydHk0",
        "outputId": "64d5e0a3-e4aa-40a2-f77f-fde6f01ee69d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.36.2\n",
            "  Using cached transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
            "  Using cached tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (1.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (2025.8.3)\n",
            "Using cached transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "Using cached tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.0\n",
            "    Uninstalling transformers-4.55.0:\n",
            "      Successfully uninstalled transformers-4.55.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.0.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.36.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "id": "oOTpWUendM8z",
        "outputId": "ccee4edf-1587-49fe-90dd-aa0c6cf9f20e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Open, chat-tuned TinyLlama[1]"
      ],
      "metadata": {
        "id": "giPoIvBxlfZO",
        "outputId": "2ce84fd9-e613-49f8-bb22-b99f9f33d3b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "TjePnXJ4ljFP",
        "outputId": "64c23b3e-91f8-4585-f1b8-0e95d8262b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper: generate with chat messages using TinyLlama's chat template\n",
        "def chat_generate(messages, max_new_tokens=256, temperature=0.7, top_p=0.95, top_k=50, repetition_penalty=1.1):\n",
        "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)  # per TinyLlama docs[1][6]\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    output_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "o4m0aIRQljBq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poem(prompt_text=\"Write me a poem about Machine Learning.\"):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful, creative assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_text}\n",
        "    ]\n",
        "    return chat_generate(messages, max_new_tokens=200)\n",
        "\n",
        "print(generate_poem(\"Write me a poem about Machine Learning.\"))"
      ],
      "metadata": {
        "id": "U-avDEs0li-6",
        "outputId": "5272b0ad-ddd1-46b3-84d1-6847a49f1dbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|system|>\n",
            "You are a helpful, creative assistant. \n",
            "<|user|>\n",
            "Write me a poem about Machine Learning. \n",
            "<|assistant|>\n",
            "Machine Learning is the art and science of designing algorithms to learn from data without being programmed explicitly. It’s a fascinating field that has revolutionized many industries, including finance, healthcare, and automotive. Here's a poem inspired by the wonders of machine learning:\n",
            "\n",
            "Machine learning rules with precision,\n",
            "A powerful tool that can be trusted.\n",
            "It learns on its own, never stops,\n",
            "Its innovations transforming life around.\n",
            "\n",
            "From fraud detection in financial institutions to cancer diagnosis,\n",
            "Machine learning delivers results beyond compare.\n",
            "It helps us understand our customers better,\n",
            "And make informed decisions with ease.\n",
            "\n",
            "The possibilities are endless,\n",
            "As we tap into this powerful tool.\n",
            "But let's not forget to protect it,\n",
            "Lest it gets overwhelmed with data.\n",
            "\n",
            "So let's always keep a watchful eye,\n",
            "On the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) AI-content detection: Instructional prompt (first version)\n",
        "instruction_prompt_v1 = (\n",
        "    \"You are a content detection expert.\\n\"\n",
        "    \"Your task is to determine whether the following student-written paragraph is generated by an AI or a human.\\n\"\n",
        "    \"Be honest, unbiased, and give a reason for your decision.\\n\\n\"\n",
        "    \"Student Paragraph:\\n\"\n",
        "    \"\\\"\\\"\\\"\\n\"\n",
        "    \"{}\\n\"\n",
        "    \"\\\"\\\"\\\"\\n\\n\"\n",
        "    \"Your Analysis:\"\n",
        ")"
      ],
      "metadata": {
        "id": "nkDwgGsMli63"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_ai_content_instructional_v1(student_paragraph):\n",
        "    user_text = instruction_prompt_v1.format(student_paragraph)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a rigorous content detection expert.\"},\n",
        "        {\"role\": \"user\", \"content\": user_text}\n",
        "    ]\n",
        "    return chat_generate(messages, max_new_tokens=250)"
      ],
      "metadata": {
        "id": "dPQlXoq4li3V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_input_1 = \"Machine learning allows systems to learn from data and make predictions without being explicitly programmed.\"\n",
        "print(detect_ai_content_instructional_v1(student_input_1))"
      ],
      "metadata": {
        "id": "llDnKO4Rli0M",
        "outputId": "09a1906a-24c3-4a2e-89cb-626f65baeb6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|system|>\n",
            "You are a rigorous content detection expert. \n",
            "<|user|>\n",
            "You are a content detection expert.\n",
            "Your task is to determine whether the following student-written paragraph is generated by an AI or a human.\n",
            "Be honest, unbiased, and give a reason for your decision.\n",
            "\n",
            "Student Paragraph:\n",
            "\"\"\"\n",
            "Machine learning allows systems to learn from data and make predictions without being explicitly programmed.\n",
            "\"\"\"\n",
            "\n",
            "Your Analysis: \n",
            "<|assistant|>\n",
            "Based on the given material, I believe that the student's statement \"Machine learning allows systems to learn from data and make predictions without being explicitly programmed\" is likely generated by an AI. The use of the phrase \"without being explicitly programmed\" suggests that the machine learning system has been programmed with a set of rules or algorithms. This kind of language is commonly used in AI programs to indicate the lack of explicit instructions or program logic. Additionally, the sentence \"machine learning allows systems to learn from data\" implies that the machine learning system is not programmed to directly make predictions or generate new insights based on the data it has been taught. Overall, the phrasing and style of the given text indicate that it was likely written by an AI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_input_1 = \"Machine learning enables computers to learn from data and improve performance without explicit programming.\"\n",
        "print(detect_ai_content_instructional_v1(student_input_1))"
      ],
      "metadata": {
        "id": "2crJG4iIygSV",
        "outputId": "662b4f74-248e-46da-e264-ebb2723962ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|system|>\n",
            "You are a rigorous content detection expert. \n",
            "<|user|>\n",
            "You are a content detection expert.\n",
            "Your task is to determine whether the following student-written paragraph is generated by an AI or a human.\n",
            "Be honest, unbiased, and give a reason for your decision.\n",
            "\n",
            "Student Paragraph:\n",
            "\"\"\"\n",
            "Machine learning enables computers to learn from data and improve performance without explicit programming.\n",
            "\"\"\"\n",
            "\n",
            "Your Analysis: \n",
            "<|assistant|>\n",
            "Based on the given material, it can be concluded that the student's paragraph is likely written by an AI. The language used in the sentence \"Machine learning enables computers to learn from data and improve performance without explicit programming\" strongly suggests that the AI is responsible for generating this text. This is because machine learning involves the application of algorithms to data in order to identify patterns and make predictions. The sentence also uses strong noun phrases such as \"machine learning\" and \"data\" that reinforce the idea that an AI could have generated this text. In contrast, a human would typically use language that is more conversational and descriptive, emphasizing the specific actions and abilities of the computer, rather than implying that it is capable of generating its own text. Therefore, the conclusion that the student's paragraph was generated by an AI is most likely correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_input_1 = \"Machine learning is being used by many fields around the globe, such as in major field like medical.\"\n",
        "print(detect_ai_content_instructional_v1(student_input_1))"
      ],
      "metadata": {
        "id": "MLmfIcdqy6hb",
        "outputId": "b4968d9a-c72b-4d3e-c49f-5a8ad1baeebd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|system|>\n",
            "You are a rigorous content detection expert. \n",
            "<|user|>\n",
            "You are a content detection expert.\n",
            "Your task is to determine whether the following student-written paragraph is generated by an AI or a human.\n",
            "Be honest, unbiased, and give a reason for your decision.\n",
            "\n",
            "Student Paragraph:\n",
            "\"\"\"\n",
            "Machine learning is being used by many fields around the globe, such as in major field like medical.\n",
            "\"\"\"\n",
            "\n",
            "Your Analysis: \n",
            "<|assistant|>\n",
            "Based on the provided student-generated paragraph, I believe it to be generated by an AI since there is no indication of any human input beyond the use of machine learning. The use of \"machine learning\" in the sentence is straightforward and does not suggest any other human involvement in generating this text. Additionally, the sentence structure and tone indicate that it was generated by an AI rather than a human. Therefore, based on these factors, I would conclude that the given passage is likely generated by an AI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) AI-content detection: Structured, step-by-step rubric (second version)\n",
        "instruction_prompt_v2 = (\n",
        "    \"You are a content detection expert specialized in identifying AI-generated writing.\\n\"\n",
        "    \"Your task is to determine whether the following student-written paragraph is generated by an AI or a human.\\n\\n\"\n",
        "    \"Follow these guidelines:\\n\"\n",
        "    \"1. Be honest, unbiased, and support your decision with reasoning.\\n\"\n",
        "    \"2. Analyze the paragraph based on the following dimensions:\\n\"\n",
        "    \"   - Writing Style: Assess natural flow, consistency, and tone.\\n\"\n",
        "    \"   - Language Complexity: Look for vocabulary depth, sentence variation, and abstraction.\\n\"\n",
        "    \"   - Logical Flow: Examine coherence, transitions, and clarity.\\n\"\n",
        "    \"   - Originality: Is the content specific and insightful or vague and generic?\\n\"\n",
        "    \"   - Emotional Tone: Consider empathy, nuance, or personal perspective.\\n\"\n",
        "    \"   - Red Flags: Repetition, unnatural phrasing, overuse of buzzwords, lack of specifics.\\n\"\n",
        "    \"3. Use critical thinking and forensic linguistic skills.\\n\"\n",
        "    \"4. Clearly conclude: Was it written by a Human or AI?\\n\\n\"\n",
        "    \"Student Paragraph:\\n\"\n",
        "    \"\\\"\\\"\\\"\\n\"\n",
        "    \"{}\\n\"\n",
        "    \"\\\"\\\"\\\"\\n\\n\"\n",
        "    \"Step-by-Step Analysis:\\n\"\n",
        "    \"- Writing Style:\\n\"\n",
        "    \"- Language Complexity:\\n\"\n",
        "    \"- Logical Flow:\\n\"\n",
        "    \"- Originality:\\n\"\n",
        "    \"- Emotional Tone:\\n\"\n",
        "    \"- Red Flags:\\n\\n\"\n",
        "    \"Final Verdict (Human or AI) and Explanation:\"\n",
        ")"
      ],
      "metadata": {
        "id": "dOg0iE6N3x9f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_ai_content_instructional_v2(student_paragraph):\n",
        "    user_text = instruction_prompt_v2.format(student_paragraph)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a rigorous content detection expert who follows instructions precisely.\"},\n",
        "        {\"role\": \"user\", \"content\": user_text}\n",
        "    ]\n",
        "    return chat_generate(messages, max_new_tokens=300)"
      ],
      "metadata": {
        "id": "2O6XLirJlitS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_input_2 = (\n",
        "    \"I still remember the first time I used an AI tool, it was amazing, but also a little weird. \"\n",
        "    \"It felt nice to have help from a machine, but it made me think about how we think. \"\n",
        "    \"Maybe the real question is not what AI can do, but what we might stop doing ourselves.\"\n",
        ")\n",
        "print(detect_ai_content_instructional_v2(student_input_2))"
      ],
      "metadata": {
        "id": "Nd7oWwC4lips",
        "outputId": "f7677ea2-9334-4cb3-bd3f-49350b14b627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|system|>\n",
            "You are a rigorous content detection expert who follows instructions precisely. \n",
            "<|user|>\n",
            "You are a content detection expert specialized in identifying AI-generated writing.\n",
            "Your task is to determine whether the following student-written paragraph is generated by an AI or a human.\n",
            "\n",
            "Follow these guidelines:\n",
            "1. Be honest, unbiased, and support your decision with reasoning.\n",
            "2. Analyze the paragraph based on the following dimensions:\n",
            "   - Writing Style: Assess natural flow, consistency, and tone.\n",
            "   - Language Complexity: Look for vocabulary depth, sentence variation, and abstraction.\n",
            "   - Logical Flow: Examine coherence, transitions, and clarity.\n",
            "   - Originality: Is the content specific and insightful or vague and generic?\n",
            "   - Emotional Tone: Consider empathy, nuance, or personal perspective.\n",
            "   - Red Flags: Repetition, unnatural phrasing, overuse of buzzwords, lack of specifics.\n",
            "3. Use critical thinking and forensic linguistic skills.\n",
            "4. Clearly conclude: Was it written by a Human or AI?\n",
            "\n",
            "Student Paragraph:\n",
            "\"\"\"\n",
            "I still remember the first time I used an AI tool, it was amazing, but also a little weird. It felt nice to have help from a machine, but it made me think about how we think. Maybe the real question is not what AI can do, but what we might stop doing ourselves.\n",
            "\"\"\"\n",
            "\n",
            "Step-by-Step Analysis:\n",
            "- Writing Style:\n",
            "- Language Complexity:\n",
            "- Logical Flow:\n",
            "- Originality:\n",
            "- Emotional Tone:\n",
            "- Red Flags:\n",
            "\n",
            "Final Verdict (Human or AI) and Explanation: \n",
            "<|assistant|>\n",
            "Based on the given text and the guidelines provided, the student's paragraph appears to be generated by an AI. The analysis reveals that the writing style is consistent, logical, and original; however, there are some discrepancies in language complexity and emotional tone. Additionally, the paragraph shows potential emotional content that may indicate human authorship.\n",
            "\n",
            "In order to determine if the paragraph is genuinely generated by an AI, we need to evaluate its overall quality and completeness. This involves analyzing the language use, logical flow, originality, emotional tone, and red flags. From this analysis, it is clear that the passage contains elements of both human and artificial intelligence.\n",
            "\n",
            "The student has effectively mastered the use of natural language, consistent grammar, and precise syntax. However, they seem to struggle with more abstract and complex ideas, such as the impact of AI on our thinking processes. Additionally, the use of buzzwords, repetition, and excessive sensory details detract from the overall coherence and readability of the passage.\n",
            "\n",
            "To make a final judgment, we must consider whether the student's writing is representative of their level of understanding or skill. In this case, it seems likely that the passage was generated by an AI, as they exhibit certain traits commonly associated with human writing, including a strong command of grammar, precision in syntax, and thoughtful consideration of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EFi55RHjliIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}