# LLM-Product Teams API Link
**AUTHOR: Arnav Ahuja (223271095)**

## 1) Overview

- We ONLY expose two endpoints to Product:
  - **POST `/api/v1/submissions`** -  _Receive a submission payload from Product_. **No LLM call here.**
  - **POST `/api/v1/evaluate`** → _Run full evaluation_ in one pass and return a **single aggregated result** (classification + confidence, rubric scores, structured feedback).


## 2) Authentication & CORS

- **Auth**: Bearer token (JWT) or service token (configurable). Reject unauthenticated requests.
- **CORS**: Enabled for the Product web origins (recommended) or `*` for development.
- **Rate limits**: Recommend per-user/app limits for `/evaluate` to control LLM costs.


## 3) Shared Schema — `EvalRequest`

```json
{
  "submission_id": "uuid-string",     // generated by Product (idempotency key)
  "assignment_id": "uuid-string",     // Product-side assignment identifier
  "student_id": "uuid-string",        // Product-side student identifier
  "domain": "teaching | psychology | it | engineering | accounting",
  "prompt": "string",                 // evaluation instruction the LLM follows
  "rubric": {
    "rubric_id": "string",
    "criteria": [
      {
        "criterion_id": "string",
        "name": "string",
        "description": "string (optional)",
        "performance_descriptors": {
          "excellent": "string (optional)",
          "good": "string (optional)",
          "average": "string (optional)",
          "needs_improvement": "string (optional)",
          "poor": "string (optional)"
        }
      }
    ]
  },
  "submission": "string",             // the student's submission text
  "actual_label": "AI | Human | Hybrid (optional)",
  "metadata": {
    "submitted_at": "ISO-8601 datetime",
    "source": "web|mobile|api",
    "language": "en-AU",
    "notes": "string (optional)"
  }
}
```

**Notes**
- `submission_id` acts as the **idempotency key** for both endpoints.
- `domain` selects few-shots in `../data/*.json`.
- `criterion_id` is the canonical join key across the pipeline.


## 4) Endpoints
### 4.1 **POST `/api/v1/submissions`** (Submission Intake)

**Purpose**: Receive the submission payload from Product and return an acknowledgement. No LLM calls.

**Behaviour**
- Validate the payload shape and types.
- Optionally **persist** to an audit store (e.g., MongoDB/SQL) keyed by `submission_id`.
- If an identical `submission_id` already exists, **treat as idempotent** and return the same `202 Accepted` response.

**Response**
```json
{
  "status": "accepted",
  "submission_id": "uuid-string",
  "received_at": "ISO-8601 datetime"
}
```


### 4. **POST `/api/v1/evaluate`** (Full Evaluation)

**Purpose**: Run the **complete evaluation** in one LLM roundtrip set and return everything needed for the UI.

**Behaviour**
1. Load domain-specific few-shots (`app/data/*.json`).
2. Build prompts via `app/prompting/templates.py` (strict JSON for feedback).
3. Call the provider through `app/models/llm_client.py` (Gemini or Mock).
4. Produce:
   - **Classification** (`AI|Human|Hybrid`) and **confidence** (0–1).
   - **Structured feedback** (overall grade, reasoning, per-criterion notes, strengths, weaknesses, improvement tips).
   - **Rubric scores derived from feedback** (no extra LLM call) in `app/services/evaluator.py`.

### Response
```json
{
  "classification": {
    "label": "Hybrid",
    "confidence": 0.78
  },
  "rubric_scores": {
    "scores": [
      { "criterion_id": "C1", "name": "Clarity", "rating": "good" }
    ]
  },
  "feedback": {
    "overall_grade": "Good",
    "reasoning": "Narrative paragraph...",
    "criteria": [
      { "criterion_id": "C1", "name": "Clarity", "rating": "good", "rationale": "..." }
    ],
    "strengths": "…",
    "weaknesses": "…",
    "improvement_tips": "…"
  }
}
```
