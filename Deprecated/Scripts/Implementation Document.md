

# TinyLlama.py – AI-Content Detection Experiments

This document summarizes the experiments conducted in **TinyLLama (2).ipynb**, including setup, helper functions, and two AI-content detection prompting strategies.

---

## Environment & Setup

**Dependencies:**
- `transformers`
- `accelerate`
- `torch`
- `sentencepiece`

**Install:**
```bash
!pip install -U transformers
pip install transformers==4.36.2 accelerate torch
pip install sentencepiece
````

**Model:**

* `TinyLlama/TinyLlama-1.1B-Chat-v1.0`
* Open, chat-tuned TinyLlama model

**Load Tokenizer & Model:**

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

MODEL_ID = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_ID,
    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,
    device_map="auto"
)
```

---

## Helper Function: `chat_generate`

This wraps TinyLlama’s chat template and `model.generate`.

**Parameters:**

* `messages`: list of system/user roles with content
* `max_new_tokens`, `temperature`, `top_p`, `top_k`, `repetition_penalty`

**Implementation:**

```python
def chat_generate(messages, max_new_tokens=256, temperature=0.7, top_p=0.95, top_k=50, repetition_penalty=1.1):
    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = tokenizer(prompt, return_tensors="pt")
    inputs = {k: v.to(model.device) for k, v in inputs.items()}
    output_ids = model.generate(
        **inputs,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=temperature,
        top_p=top_p,
        top_k=top_k,
        repetition_penalty=repetition_penalty,
        eos_token_id=tokenizer.eos_token_id,
        pad_token_id=tokenizer.eos_token_id
    )
    return tokenizer.decode(output_ids[0], skip_special_tokens=True)
```

---

## Creative Sample: Poem Generation

Simple test of model creativity.

```python
def generate_poem(prompt_text="Write me a poem about Machine Learning."):
    messages = [
        {"role": "system", "content": "You are a helpful, creative assistant."},
        {"role": "user", "content": prompt_text}
    ]
    return chat_generate(messages, max_new_tokens=200)

print(generate_poem("Write me a poem about Machine Learning."))
```

---

## AI-Content Detection

Two instructional prompt styles were tested for detecting whether text was AI- or human-written.

---

### 1. Instructional v1 (Concise)

**System:**
“You are a rigorous content detection expert.”

**User:**
Directive to decide AI vs. Human with justification, followed by the student paragraph.

**Prompt Template:**

```python
instruction_prompt_v1 = (
    "You are a content detection expert.\n"
    "Your task is to determine whether the following student-written paragraph is generated by an AI or a human.\n"
    "Be honest, unbiased, and give a reason for your decision.\n\n"
    "Student Paragraph:\n"
    "\"\"\"\n"
    "{}\n"
    "\"\"\"\n\n"
    "Your Analysis:"
)
```

**Wrapper Function:**

```python
def detect_ai_content_instructional_v1(student_paragraph):
    user_text = instruction_prompt_v1.format(student_paragraph)
    messages = [
        {"role": "system", "content": "You are a rigorous content detection expert."},
        {"role": "user", "content": user_text}
    ]
    return chat_generate(messages, max_new_tokens=250)
```



---

### 2. Instructional v2 (Structured Rubric)

**System:**
“You are a rigorous content detection expert who follows instructions precisely.”

**User:**
Directive with rubric specifying analysis dimensions.

**Prompt Template:**

```python
instruction_prompt_v2 = (
    "You are a content detection expert specialized in identifying AI-generated writing.\n"
    "Your task is to determine whether the following student-written paragraph is generated by an AI or a human.\n\n"
    "Follow these guidelines:\n"
    "1. Be honest, unbiased, and support your decision with reasoning.\n"
    "2. Analyze the paragraph based on the following dimensions:\n"
    "   - Writing Style: Assess natural flow, consistency, and tone.\n"
    "   - Language Complexity: Look for vocabulary depth, sentence variation, and abstraction.\n"
    "   - Logical Flow: Examine coherence, transitions, and clarity.\n"
    "   - Originality: Is the content specific and insightful or vague and generic?\n"
    "   - Emotional Tone: Consider empathy, nuance, or personal perspective.\n"
    "   - Red Flags: Repetition, unnatural phrasing, overuse of buzzwords, lack of specifics.\n"
    "3. Use critical thinking and forensic linguistic skills.\n"
    "4. Clearly conclude: Was it written by a Human or AI?\n\n"
    "Student Paragraph:\n"
    "\"\"\"\n"
    "{}\n"
    "\"\"\"\n\n"
    "Step-by-Step Analysis:\n"
    "- Writing Style:\n"
    "- Language Complexity:\n"
    "- Logical Flow:\n"
    "- Originality:\n"
    "- Emotional Tone:\n"
    "- Red Flags:\n\n"
    "Final Verdict (Human or AI) and Explanation:"
)
```

**Wrapper Function:**

```python
def detect_ai_content_instructional_v2(student_paragraph):
    user_text = instruction_prompt_v2.format(student_paragraph)
    messages = [
        {"role": "system", "content": "You are a rigorous content detection expert who follows instructions precisely."},
        {"role": "user", "content": user_text}
    ]
    return chat_generate(messages, max_new_tokens=300)
```



## Summary

* **Instructional v1:** Concise directive → quick judgments, minimal structure.
* **Instructional v2:** Rubric-driven → structured, detailed reasoning, closer to Gemma’s style.
* This setup enables **qualitative comparison** of TinyLlama vs Gemma-2B-IT on rubric-following and AI-content detection.


