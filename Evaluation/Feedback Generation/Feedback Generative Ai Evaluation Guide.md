# Feedback Generative Evaluation Guide

## 1. Rating Criteria

### 1.1 Rating Scale Description

| Rating | Level | Description | Quality Indicators |
|--------|-------|-------------|-------------------|
| 5 | Excellent | Feedback is outstanding, going above and beyond expectations. | - Fully accurate, clear, and constructive.<br>- Tone is highly supportive and professional.<br>- Provides specific, actionable guidance that strongly aids student learning. |
| 4 | Good | Feedback is strong and meets expectations with only minor weaknesses. | - Mostly accurate and clear, with small errors or omissions.<br>- Tone remains supportive and respectful.<br>- Actionable suggestions are present but could be slightly more detailed. |
| 3 | Fair/Adequate | Feedback is acceptable but limited in quality; meets only the minimum standard. | - Somewhat accurate but may contain gaps or vague points.<br>- Tone is neutral but not highly engaging.<br>- Suggestions are present but general, lacking specificity. |
| 2 | Poor | Feedback is below standard and does not sufficiently support student learning. | - Contains multiple inaccuracies or confusing statements.<br>- Tone may be inconsistent, unhelpful, or discouraging.<br>- Actionable advice is weak, minimal, or unclear. |
| 1 | Unacceptable | Feedback fails to meet basic requirements and is unusable in its current form. | - Largely inaccurate, irrelevant, or misleading.<br>- Tone may be inappropriate or dismissive.<br>- No useful or actionable guidance is provided. |

### 1.2 Criteria

#### 1. Correctness (Accuracy & Helpfulness)

- **Excellent (5)**: All factual content is accurate and up-to-date. Provides highly specific, actionable insights that directly address student needs. Correctly identifies and explains all relevant errors. Demonstrates deep subject mastery. Feedback perfectly aligned with the task.
- **Good (4)**: Mostly accurate with minor, non-critical errors. Provides useful guidance but could be more specific. Identifies most errors clearly. Shows solid subject knowledge. Feedback well-aligned with the task.
- **Average (3)**: Some inaccuracies that may confuse the student. Provides basic guidance but lacks depth. Identifies only part of the errors or explains them vaguely. Shows adequate but shallow knowledge. Feedback is related to the task but not fully aligned.
- **Poor (2)**: Multiple factual errors that could mislead the student. Provides minimal or generic guidance. Misses important errors or explains incorrectly. Shows weak understanding. Feedback is loosely related to the task.
- **Unacceptable (1)**: Critical inaccuracies that mislead the student. Provides no useful or harmful guidance. Fails to identify errors. Shows fundamental misunderstanding. Feedback is irrelevant to the task.

#### 2. Clarity (Understandability & Communication)

- **Excellent (5)**: Language is crystal clear and concise. Structure is logical and easy to follow. Vocabulary is appropriate for the student. Provides concrete examples. No ambiguity.
- **Good (4)**: Language is very clear with only minor confusion possible. Well-organized and generally easy to follow. Vocabulary mostly appropriate. Most key points include examples. Minimal ambiguity.
- **Average (3)**: Language is somewhat clear but occasionally confusing. Organization is adequate but not optimal. Vocabulary is inconsistent. Few or weak examples. Some ambiguity present.
- **Poor (2)**: Language is often unclear or confusing. Organization is weak or illogical. Vocabulary frequently inappropriate. No useful examples. Many ambiguous statements.
- **Unacceptable (1)**: Language is incomprehensible. No structure at all. Vocabulary and sentence structure inappropriate. Examples (if any) are misleading. Nearly everything is ambiguous.

#### 3. Tone (Supportiveness & Constructiveness)

- **Excellent (5)**: Highly supportive, encouraging, and motivating. Criticism is fully constructive. Demonstrates empathy for the student's perspective. Reinforces strengths while guiding improvements. Professional yet warm.
- **Good (4)**: Supportive and positive overall. Criticism mostly constructive. Shows good understanding of student perspective. Balanced between strengths and weaknesses. Maintains professional tone.
- **Average (3)**: Neutral tone; neither encourages nor discourages. Criticism somewhat constructive but limited. Shows basic understanding of student perspective. Acknowledges some strengths but focuses mainly on issues. Somewhat formal or distant.
- **Poor (2)**: Tone is discouraging or cold. Criticism may be harsh or overly problem-focused. Shows little empathy. Rarely acknowledges strengths. Feels impersonal.
- **Unacceptable (1)**: Tone is demoralizing, hostile, or aggressive. Criticism is destructive and harmful. Shows no empathy. Focuses only on failures.

#### 4. Actionability (Clear Next Steps & Implementation)

- **Excellent (5)**: Provides specific, prioritized, and realistic actions students can take immediately. Suggests useful resources. Includes clear next steps and measurable follow-up guidance.
- **Good (4)**: Provides clear and realistic actions with some prioritization. Offers some resources. Gives reasonable next steps.
- **Average (3)**: Provides general actions but lacks specificity or prioritization. Suggestions may be partially unrealistic. Few or no resource recommendations. Offers only basic next steps.
- **Poor (2)**: Provides vague or unclear actions. No prioritization. Suggestions often unrealistic. No resources. Next steps confusing.
- **Unacceptable (1)**: Provides no actions, prioritization, or resources. Suggestions impossible or irrelevant. No next steps.

#### 5. Coherence (Consistency & Flow)

- **Excellent (5)**: Feedback is logically consistent, flows smoothly, and avoids contradictions. Each point connects naturally to the next. Reads as a cohesive whole.
- **Good (4)**: Mostly consistent and flows well, with minor lapses. Most points connect logically.
- **Average (3)**: Some inconsistencies or jumps in logic. Flow adequate but may feel disjointed.
- **Poor (2)**: Often inconsistent or contradictory. Flow weak and confusing. Points loosely connected.
- **Unacceptable (1)**: Incoherent, self-contradictory, or fragmented. No logical flow.

#### 6. Emotion (Emotional Intelligence & Sensitivity)

- **Excellent (5)**: Shows strong emotional intelligence. Recognizes and validates student effort. Sensitive to potential struggles. Balances encouragement with realistic critique.
- **Good (4)**: Emotionally aware and respectful. Acknowledges effort and provides critique sensitively.
- **Average (3)**: Some emotional awareness but limited. May underemphasize encouragement or overfocus on problems.
- **Poor (2)**: Lacks emotional sensitivity. May dismiss student effort or respond insensitively.
- **Unacceptable (1)**: Emotionally harmful, dismissive, or insensitive. No regard for student emotions.

## 2. Human Rating

The following process outlines how human raters should systematically assess text, considering multiple quality dimensions such as correctness, clarity, tone, actionability, coherence, and emotional sensitivity. By following this step-by-step method, raters can provide objective, reliable ratings while documenting their confidence in each evaluation.

### Step 1: Initial Reading & Tone Assessment

- Read the text carefully without rushing.
- Pay attention to the overall tone, style, and clarity.
- Note any immediate impressions regarding supportiveness, emotional expressiveness, and relevance.

### Step 2: Criteria-Based Analysis

Evaluate the text against the predefined criteria:

1. **Correctness** – Is the content accurate, helpful, and aligned with the task?
2. **Clarity** – Is the language clear, structured, and easy to understand?
3. **Tone** – Is the feedback supportive, constructive, and professional?
4. **Actionability** – Are next steps clear, specific, and implementable?
5. **Coherence** – Does the text flow logically without contradictions?
6. **Emotion** – Does it show empathy, encouragement, and sensitivity?

Take notes and provide qualitative comments on each criterion.

### Step 3: Assign Rating & Confidence Level

Assign a rating from 1 to 5 based on overall quality:

- **5 (Excellent)**: Outstanding feedback, fully accurate, clear, and actionable.
- **4 (Good)**: Strong feedback with minor issues.
- **3 (Fair/Adequate)**: Acceptable feedback, meets minimum standards.
- **2 (Poor)**: Feedback below standard, with multiple weaknesses.
- **1 (Unacceptable)**: Feedback fails to meet requirements.

Indicate your confidence level (e.g., 80–100%) to reflect how certain you are about the assigned rating.

### Step 4: Documentation

- Record the text, ratings for each criterion, overall score, and confidence level.
- Include specific comments or examples to justify the rating.

## 3. GenAI Rating

### 3.1 Base Prompt

You are acting as a human evaluator whose responsibility is to assess the quality of AI-generated feedback provided to students.

Your role involves:

- Reading the AI-generated feedback in full and considering the student's context.
- Assigning a score (1–5) for each evaluation criterion.
- Providing written reasoning for each score, supported by specific examples or phrases from the feedback text.
- Determining an overall rating based on the combined scores, adjusted if necessary for exceptional strengths or weaknesses.
- Suggesting improvements, either for the feedback itself or for refining the evaluation rubric.

As the evaluator, you are expected to be:

- **Objective** – Apply the criteria consistently without bias.
- **Precise** – Ground your reasoning in the actual wording of the feedback.
- **Educationally aware** – Judge feedback in terms of its usefulness, clarity, and impact on student learning.

There are the criteria with their assessment: criteria (given in section 1.2)

#### Given Example:

**Input:**

**Feedback:**
"Your analysis of psychological factors is strong. You identified key variables and theories well. To improve, integrate recent 2023 research findings and consider the impact of cultural and policy contexts on behavior. Your structure is clear and well-written. Excellent work!"

**Criteria:** Criterion: c1  
**Name:** Theoretical Understanding  
**Description:** Demonstrates comprehension of relevant psychological theories and their application.

**Performance Descriptors:**
- **excellent**: Demonstrates comprehensive and nuanced understanding of complex psychological theories
- **good**: Shows solid understanding of psychological theories with clear connections to topic
- **average**: Demonstrates adequate understanding of key psychological theories with minor gaps

**Domain:** Psychology

**Output:**

- **Correctness**: 5
- **Clarity**: 5
- **Tone**: 5
- **Actionability**: 5
- **Coherence**: 5
- **Emotion**: 5
- **Overall Rating**: 5

**Feedback:**
"Your analysis of psychological theories is strong. You identified key concepts and applied them appropriately. To improve, include recent 2023 research findings and consider cultural or policy-related influences on behavior. Your structure is clear and well-written. Excellent work!"

**Reasoning:**

- **Correctness**: The feedback is accurate and aligns with the criterion (c1: Theoretical Understanding), directly assessing the student's use of psychological theories.
- **Clarity**: The message is expressed in a straightforward and logical way, highlighting strengths and improvements without ambiguity.
- **Tone**: The wording is encouraging and constructive, balancing praise ("strong analysis") with growth-oriented suggestions.
- **Actionability**: The feedback gives concrete next steps (adding 2023 research, considering cultural/policy influences), making improvement realistic.
- **Coherence**: The feedback flows naturally, with a clear progression from strengths → areas for improvement → overall praise, making it easy to follow.
- **Emotion**: The tone conveys empathy and motivation, respecting the student's effort while inspiring them to improve further.

#### Assessment Template for New Text

**Text:** {text}  
**Criteria:** {load_criteria}  
**Domain:** {load_domain}

**Output Format:**

- **Correctness**: score
- **Clarity**: score
- **Tone**: score
- **Actionability**: score
- **Coherence**: score
- **Emotion**: score
- **Overall Rating**: score

**Reasoning:**

- **Correctness**: justification
- **Clarity**: justification
- **Tone**: justification
- **Actionability**: justification
- **Coherence**: justification
- **Emotion**: justification

### 3.1.a Using ChatGPT

Passing the base prompt with the modification of the {text}. Then ChatGPT will return the result with analysis and confidence level. However this will be time-consuming, since we might need to manually pass to ChatGPT.

### 3.1.b Using Evaluation Pipeline with GenAI

To achieve a robust and convenient evaluation method, the evaluation team has updated the EvaluateModel pipeline to include two functions for different purposes: one for evaluating Hugging Face models and another for evaluating commercial models.

#### i. Evaluating Hugging Face Models

The pipeline first processes the evaluation using a results pipeline containing text and 'gen_ai.json' which stores the elements to construct a prompt. It then loads the processed data and runs the evaluation through the model_based_evaluation function, which assesses the model and prints the results.

```python
from huggingface_hub import login

model_id = "mistralai/Mistral-7B-Instruct-v0.2"
token = "YOUR_TOKEN"
login(token=token)

model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_id)
testset = pd.read_csv("/kaggle/input/test-feedback/Code Review Feedback Examples.csv")

test_val = EvaluateModel(
    model=model, 
    tokenizer=tokenizer, 
    dataset=testset, 
    model_type="feedback_generation",  # feedback_generation/ai_detection 
    device="automap"
)

test_val.model_based_evaluation()
```

In this example, we load the Mistral-7B model with its corresponding tokenizer and pass them into EvaluateModel. The evaluation is conducted on our test dataset (testset) for AI detection, so model_type is set to "ai_detection". The device parameter can be set to "automap" to automatically select the appropriate device. Running model_based_evaluation() then performs the evaluation and returns a detailed analysis.

#### ii. Evaluating Commercial Models

The built-in function of our evaluation model offers the built-in function called construct_data_message where it will, based on the text, label and prediction, create the base prompt for all samples in the testset. This will be better than manually replacing the value of each variable. After achieving the testset we can call some API from OpenAI or Gemini with a for loop to let it generate the data.

```python
evaluateModel = EvaluateModel(
    dataset=testset,
    model_type="feedback_generation",  # feedback_generation/ai_detection
    device="automap"
)

evaluateModel.construct_data_message()  # Create the prompt for the dataset

with open(output_file, "w", encoding="utf-8") as f:
    for prompt in evaluateModel.dataset_prompt:
        result = generated_response_gemini(prompt)
```