**Final Assessment on Phi2 model after evaluation results** 

1. **Poor Accuracy in AI Detection**

   Across  all  domains  (Accounting,  Engineering,  IT,  Psychology, Teaching), Phi-2 consistently showed low detection accuracy: 

- **Accounting**: 30% accuracy, while human raters reported only 16% accuracy. 
- **Engineering**: 16% accuracy, confirmed by human evaluation at 16%. 
- **Psychology & Teaching**: Both around 33% accuracy. 
- Even  in  its  “best”  domain  (IT)  has  only  reached  to  66% accuracy. 
- This  means  Phi-2  misclassified  2/3  of  texts  overall,  often labeling human-written texts as AI with very high confidence (90–97%), showing overconfidence in wrong predictions. 
2. **Misclassifications:** 

   Human criteria reveal clear patterns: 

- Human  texts  with  personal  perspective,  anecdotes,  or emotional tone were wrongly flagged as AI. 
- AI-generated academic summaries were frequently mistaken for Hybrid, due to polished style. 
- Overall, false positives (humans flagged as AI) were frequent (e.g., 3/6 in Teaching, 2/6 in IT). 
- Through all the submissions Phi2 was not able to detect any human written submissions. 
- These  errors  mean  phi2  cannot  be  trusted  in  educational settings as it is unfairly penalizes human work. 
3. **Feedback generation is generic and misaligned:** 
- Genai feedback ratings were often excellent across all criteria with little variation. 
- Human criteria evaluation gave lower, more realistic ratings when compared to genai. 
- Both evaluations show phi2’s feedback often scored 3/5 for actionability meaning it lacked to give practical improvement tips. 
- Phi-2 produces only positive feedback but fails to give the constructive criticism that students need. 
4. **Conclusion:** 
- Extremely low accuracy in AI detection** (as low as 16% in some domains). 
- Systematic  misclassifications  that  unfairly  penalize  human writing. 
- Feedback  generation  is  generic,  inflated,  and  low  in actionability, failing to support learning. 
- Strong  misalignment  with  human  evaluation,  making  it unsuitable for real-world educational use. 
